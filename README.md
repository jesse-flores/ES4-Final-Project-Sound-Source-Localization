# ES4-Final-Project-Sound-Source-Localization
This project implements a real-time acoustic direction-finding system that determines the compass direction of a sound source using three I2S MEMS microphones connected to an FPGA. The system displays the detected direction on eight LEDs representing the cardinal and intercardinal compass directions (N, NE, E, SE, S, SW, W, NW).

ChatGPT was used in developing python script and math (gemini in troubleshooting) as well as idea to make circular buffer work.

Additional documentation can be found here: (ADD LINK LATER)

![](diagram.jpeg "Block Diagram")

Hardware:

iCE40UP5K (Upduino 3.0)

![](pico_ice_front.jpg "iCE40UP5K front")
![](pico_ice_back.jpg "iCE40UP5K back")

I2S MEMS Microphone

![](I2SMEM.png "iCE40UP5K back")


Brief Module Overviews:

cgen.sv: Takes in the internal 48 MHz clock and uses it to generate two clocks, the lrclk and bclk. This module increments the value of a counter by one every clock cycle. The lrclk and bclk are generated by selecting a specifc bit on the counter.  The lrclk is high when the 9th bit of the counter is high and the 4th bit of the counter is high, the bclk is high. Doing this, the blck now has a generated frequency of about 3MHz and the lrclk a frequency of 46.875 KHz.


i2s_mic_rx.sv: This module takes in all three clocks as well as one bit inputs from the i2s microphone. On the rising edge of the bitclock a new value is read in from the microphone and is stored inside of a shift register. When all 32 bits have been read from the microphone, the audio sample is filtered to get rid of dc bias in the audio.

tdoa_stream.sv: Takes in the clock along with a reference and target audio sample. This module takes the 4 most significant bits of each of th samples and stores them in a buffer of references and target audio samples respectively. Utilizing various states, data data is collected to populate the buffers. From here, the best lag value is found and outputted (NOT FINISHED)

Compass_solver.sv: Takes in the delays for each mic and utlizes them in a look up table for the expected values. The expected values are then compared to the actual delays in order to calculate a difference. From here each LED has a score calculated and asssociated to it. The LED with the highest score is  given a digital high indicating that it should turn on.

Top,sv: The main file. Calls instances of the previous classes in order to collect and process data from the microphones in order to locate the direction of sound.  













